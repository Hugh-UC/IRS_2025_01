// To add: what packages are needed


= TM ROS 2 - Developer Guide
:site-section: DeveloperGuide
:toc:
:toclevels: 3
:toc-title: Table of Contents
:toc-placement: preamble
:icons: font
:sectnums:
:imagesDir: images
:librariesDir: ../libraries
:stylesDir: stylesheets
:xrefstyle: full
:experimental:
:linkattrs:
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:warning-caption: :warning:
endif::[]

:url-repo: https://github.com/guanyewtan/Omron_TM_ROS2
:url-ug: https://github.com/guanyewtan/Omron_TM_ROS2

Last updated: `24 June 2021` By: `Tan Guan Yew`(link:https://github.com/guanyewtan[guanyewtan]) and Zeon Chua (link:https:https://github.com/CFZeon[CFZeon])


== Getting Started
[[prerequisites]]
=== Prerequisites


. **Ubuntu 20.04 LTS (Focal Fossa)**
+
See link:https://ubuntu.com/download/desktop[Ubuntu] webpage for installation instructions (version 20.04 release).
+
These packages were developed and tested using only Ubuntu Linux OS. Although ROS 2 is officially supported on multiple platforms including Windows OS, *Ubuntu Linux OS is preferred* since there is greater support for packages on Ubuntu platform.

. **Robot Operating System 2 (ROS 2) Foxy Fitzroy Release**
+
Download and installation instructions can be found link:https://docs.ros.org/en/foxy/Installation/Linux-Install-Debians.html[here].
+
[NOTE]
Installing via the Ubuntu terminal and debian packages is the most convenient way to install ROS 2.
+
__Omron_TM_ROS2__ is currently supported on ROS 2 Foxy only.
+
This guide assumes you know the basics of using the ROS 2 environment. If you are new to ROS 2, please follow their series of link:https://docs.ros.org/en/foxy/Tutorials.html[tutorials] to get started with using ROS 2.
+
You will need to complete at least the `Beginner Level` tutorials. 

. **Python 3**
+
The python scripts and Classes used to run the pick and place program are developed and written in link:https://www.python.org/downloads/release/python-385/[Python 3.8.5].
+
Information on python Classes can be found link:https://docs.python.org/3/tutorial/classes.html[here].

. **TMflow v1.82.3400**
+
The TM set up instructions here assumes you are using `TMflow v1.82.3400` to set up the listen node (as well as other nodes). The packages are also compatible with TMflow v1.80.5300. Other versions have not been tested.

. **Pymodbus**
+
Modbus communication is used alongside the TM drivers to obtain robot information, such as joint positions, and is also capable of controlling many of the TM robot's features. Documentation for Pymodbus can be found link:https://pymodbus.readthedocs.io/en/latest/readme.html[here].

=== Hardware Requirements
This package assumes a specific hardware configuration in order to work correctly.

. **TM5-900**
+
This will be the TM robot you will be controlling via this package.
[NOTE]
This package has also been tested to work on the TM12-1300. However, some configurations must be changed to support the proper visualization for the TM12.

. **Host machine running ROS 2**
+
This is the machine that communicates with the TM via an ethernet connection. The ROS 2 packages are run on this machine.
+

. **Robotiq IO Coupling**
+
The packages were designed using the Robotiq IO coupling wrist attachment to control the gripper via digital IO. More information on the IO coupling can be found link:https://elearning.robotiq.com/course/view.php?id=3&section=5[here].

==== Hardware Overview
The diagram below gives an overview of how the communications will be configured:

.Overview of communication [[bookmark]]
image::HardwareConnection.png[]

==== Hardware Connection
The diagram below shows the port on the TM interface which the ethernet cable is connected to (from the host machine). Please use the port indicated by the red box since it is the only one that supports Modbus. 

.TM Controller
image::TM_Interface.png[]

=== Set Up TM
This package utilises the link:https://github.com/TechmanRobotInc/tmr_ros2[tmr_ros2] packages for the TM drivers to communicate with the robot.
In order to use this package, your TM must be configured correctly to communicate with the host machine running this ROS 2 package. This configuration will be done via `TMflow`. This guide assumes that you have basic knowledge on using the `TMflow` software. More information on the TMflow software can be found in the Software Manual, TMflow SW1.82, 19888-400 RevH.

==== TM Listen/Vision Node Setup

In TMflow, create a flow project, then choose the __Listen__ node, __Vision__ node, and the __Goto__ node.

.Project Flow
image::ProjectFlow.png[]

[WARNING]
To ensure that the demo program works properly, uncheck the "Start at Initial Position" setting.

.Setting location to remove initial position
image::visionremoveinitial.png[]

[NOTE]
This step can be skipped if you have imported `ROS2_teach.zip` provided in the repository files, found under the TM_Export folder. Instructions for importing the zip is located in section 5.8.6 of TMflow Software Manual.


==== TM System/Network Setup
. Go to System -> Network setting page and enter the network parameters of the robot
+
.Network Parameters
image::NetworkSetup.png[]
. Go to Setting -> Connection -> Ethernet Slave
+
Select the Data Table Setting button and check the following boxes (__make sure the Ethernet Slave is DISABLED or you will be unable to change the settings__):
+
 - [x] Robot_Error
 - [x] Project_Run
 - [x] Project_Pause
 - [x] Safeguard_A
 - [x] ESTOP
 - [x] Camera_Light
 - [x] Error_Code
 - [x] Joint_Angle
 - [x] Coord_Robot_Flange
 - [x] Coord_Robot_Tool
 - [x] TCP_Force
 - [x] TCP_Force3D
 - [x] TCP_Speed
 - [x] TCP_Speed3D
 - [x] Joint_Speed
 - [x] Joint_Torque
 - [x] Project_Speed
 - [x] MA_Mode
 - [x] Robot Light
 - [x] Ctrl_DO0~DO7
 - [x] Ctrl_DI0~DI7
 - [x] Ctrl_AO0
 - [x] Ctrl_AI0~AI1
 - [x] END_DO0~DO3
 - [x] END_DI0~DI2
 - [x] END_AI0
+

. Set the Data Format to __BINARY__ and press save.

==== TM Modbus Setup
. Go to Setting -> Connection -> Modbus
+
Ensure the TCP Modbus Slave is __ENABLED__
+
.Modbus
image::Modbus.png[]


=== Set Up Host Machine

The host machine is used to run the python scripts which use both the TM Drivers and the ROS 2 packages to communicate with the TM robot. Ensure that your machine meets the requirements in <<prerequisites>>.

==== IP Address
Ensure that the ip address of the host machine and the TM robot(<<TM System/Network Setup>>) have the same subnet. Instructions on how to change the static ip address in Ubuntu 20.04 can be found link:https://www.linuxtechi.com/assign-static-ip-address-ubuntu-20-04-lts/#:~:text=Assign%20Static%20IP%20Address%20on%20Ubuntu%2020.04%20LTS%20Desktop&text=Login%20to%20your%20desktop%20environment,and%20then%20choose%20wired%20settings.&text=In%20the%20next%20window%2C%20Choose,gateway%20and%20DNS%20Server%20IP.[here]


==== Host Machine ROS 2 Package Set Up
Once you have your network set up correctly, you need to configure this ROS 2 package to work correctly in your host machine.

First, make sure you have installed ROS 2 as described in <<prerequisites>>.

. Clone this repository to a directory of your choice with: 
+
....
cd <directory>
git clone https://github.com/guanyewtan/Omron_TM_ROS2
....
. Enter the folder with:
+
....
cd Omron_TM_ROS2
....
. Build all package with:
+
....
colcon build --symlink-install
....
+
> Depending on your machine, this can take a while to build.
If you receive a warning saying "no such command", follow the intructions link:https://docs.ros.org/en/foxy/Tutorials/Colcon-Tutorial.html#install-colcon[here].

[NOTE]
You might need to install some missing packages if you didn't already have them. They can be installed with `sudo apt install ros-foxy-control-msgs`.

==== TM ROS 2 Driver Setup/Usage

. Enter your ROS 2 workspace and source the ROS2 environment:
+
```
source /opt/ros/foxy/setup.bash
cd <workspace>
source ./install/setup.bash
```

. Ensure that TM Robot's operating software (__TMflow__) system/network settings have been set and the __Listen node__ is running (run the project above)

. Run the driver to maintain the connection with TM Robot:
+
```
ros2 run tm_driver tm_driver <robot_ip_address>
```
+
Example: `ros2 run tm_driver tm_driver 192.168.2.10`, if the <robot_ip_address> is 192.168.2.10
+
Now, the user can use a __new terminal__ to run each ROS node or command, but don't forget to source the correct setup shell files after starting a new terminal!
+
The TM driver is required to be running as long as a connection to the listen node of the TMflow program is required.
+
For more information on the TM Drivers, click link:https://github.com/TechmanRobotInc/tmr_ros2/blob/master/README.md[here].



== Software Design
[[architecture]]
=== Architecture
An overview of this package architecture is summarised in the diagram below:

.Overview of package
image::SoftwareOverview.png[]

=== Socket TCPlistener
Users can establish a socket TCPlistener in the listen node to connect to external device and communicate based on the packet format.

All features available in TM ROBOT Function can be operated in the listen node. For more information on the listen node, please refer to page 181 of the __TM Expression Editor and Listen Node Reference Guide__.

The TM Driver utilises TMSCT and TMSTA communication packages to send external scripts and obtain the status or properties of the TM respectively. Below is an example of how the TM Driver uses these 2 communication packages to communicate through the Socket TCPlistener:

. TM Driver sends a PTP (point-to-point) movement command via a ROS2 service client using TMSCT packages to the TM Robot. When the command has been successfully sent, an acknowledgement is sent back to the host machine.

. A queue tag is sent via TMSCT communication packages and its status monitored using TMSTA, to check if a motion command has been completed.

=== Modbus
Users can use Modbus Client to read or write the parameters and save them in the robot register, such as position, posture and IO status. Users can program with the obtained parameters or monitor the status of robot. TM Robot provides two protocol versions of Modbus: Modbus TCP and Modbus RTU for users to obtain data from the external Modbus device or robot register. Modbus TCP is used for these packages.

.Modbus Protocol
image::ModbusProtocol.png[]

There are limitations to the capabilities of the TM Drivers, which is why Modbus is being used to send and receive information unobtainable by the drivers, such as getting the coordinates of the current base in the project flow or starting the project from outside the listen node.

The pymodbus libraries are used to communicate with the modbus servers.


=== RViz Visualisation
The `RViz` package allows a 3D model TM robot to be displayed in a separate window for real time visualisation.

This package uses the joint states generated from the TM driver as well as the robot description publisher to generate the model and display it in its current position.

To understand how `RViz Visualisation` is structured with the entire ROS package and communicates with LD, see <<architecture>>.

`RViz Visualisation` has three nodes, they are summarised as below:

[cols="1,1a", options="header"]
.TM Visualisation nodes
|===
|**Node name**
|**Description**

|tm_driver
|
This node is responsible for publishing the joint states that the RViz program subscribes to.

Using this information, it updates the position of the TM shown on RViz.

|robot_description
|
This node is responsible for pubishing the .urdf information that the RViz program uses to display the model of the robot, as well as know the transform of each component of the robot relative the another point.

|static_transform_publisher
|
This node is responsible for publishing a transform which sets the base of the 3D model to the zero coordinate.

|pp_marker
|
This node is responsible for publishing a transform and marker that represents an object picked up by the grippers.

|tcp_publisher
|
This node is responsible for publishing a transform to the flange, representing the location of the TCP that is set in TMFlow
|===


== Implementation
=== Pickplace Program
The pickplace package allows the user to create a pick and place program, requiring only a one time setup. The pickplace program will then continuously run a vision guided pick and place operation.

[NOTE]
This implementation was designed using a TM Landmark attached to the object to be picked, and another TM landmark to find the place location. However, it is possible for the TM vision to locate other visual features on objects, depending on how the vision job is trained in TMFlow.

These 2 landmarks act as the vision base for the pick and place, and the vision job takes into account the tilt and rotation of the TM landmark (so long as it can be seen clearly by the camera)

There are 2 stages to the program: a setup phase, where the user sets the location of TM to view the pick and place landmarks as well as the pick and place locations, and an execution phase, where the pick and place operation will run based on the coordinates set in the setup phase.

==== Setup
The teach_setup.py script runs through a sequence of instructions for the user to record the pick and place positions of an object, as well as the positions to view their respective landmarks. The following diagram shows the flow of the setup program:

.Pickplace setup flow
image::teachsetup2.png[]
. In one terminal, run `server.launch.py` to ensure that the teach_setup program can communicate with the TM robot with
+
....
ros2 launch pickplace server.launch.py robot_ip:=<robot_ip_address>
....
+
. In another terminal, run the program to initiate the setup process, replacing `robot_ip_address` with the ip address of the TM robot.
+
....
ros2 run pickplace teach_setup <robot_ip_address>
....
[NOTE]
Remember to source the ROS2 packages again in the new terminal or you might not be able to run the setup program properly.
+
. Move the robot to an initial position to start with on program launch, then press kbd:[ENTER]
+
image::prompt6.png[]
+
. Enter the name of the vision base that will be created in the TMflow program by the vison job.
+
image::prompt7.png[]
+
image::visionjobname.png[]

[NOTE]
The vision base name is the name of the vision job with `vision_` appended to the front. For example, if the vision job name is `myvisionjob`, the vision base name will be `vision_myvisionjob`.

. Move the TM arm to the landmark viewing position for picking the object.
+
image::viewpick.gif[]
+
. Press the play button on the robot stick. You should hear the robot beep 3 times to signal the start of the TMflow project.
+
image::robotstick_play.jpg[]
+
. Hit kbd:[ENTER] to start the vision job. 
+
image::prompt2.png[]
+
. Wait for the vision job to complete, then press the stop button on the robot stick. The robot should beep once.
[NOTE]
It is advised to open up the vision job to check if the landmark can be detected, or this might cause problems with detection during the execution process.
+
image::robotstick_stop.jpg[]
+
. Move the TM arm to the pick position.
+
image::pick.gif[]
+
[WARNING]
Ensure that the object remains in the SAME POSITION as it was during the vision job.
+
. Hit kbd:[ENTER] to close the grippers and record the position, then move the TM arm to the landmark viewing position for placing the object.
+
image::prompt3.png[]
+
image::viewplace.gif[]
+
. Press the play button on the robot stick. The robot should beep 3 times.
. Hit kbd:[ENTER] to start the vision job.
[NOTE]
It is advised to open up the vision job to check if the landmark can be detected, or this might cause problems with detection during the execution process.
. When the vision job is done, press the stop button on the robot stick. The robot should beep once.
+
image::prompt4.png[]
+
. Move the TM arm to the place position and hit kbd:[ENTER], which releases the grippers and records the position.
+
image::prompt5.png[]
+
image::place.gif[]
+
. A JSON file will be generated containing the coordinates of the landmark viewing positions, the pick and lace positions as well as the name of the vision job, to be used in the execution stage.

==== Custom End Effector TCP settings
Should you wish to configure your own end effector instead of the Robotiq 2F-85 gripper, there are a few steps to be followed.

. Return to TMFlow

. Go to Setting -> TCP Setting -> Manual input parameters of TCP

. Set the appropriate position of your TCP relative to the robot flange

. Click Apply

Your TCP is now configured for use in this package.

==== Execution

The pickplace_program.py script takes the coordinates obtained from the setup stage and implements a continuous pick and place program, with an RViz terminal showing the real time pose of a 3D model of the TM robot. The flow of the program is shown below:

.Pickplace execution flow
image::pickplaceflow.png[]

. . Run the launch file to execute the program, replacing `robot_ip_address` with the ip address of the TM robot.
+
....
ros2 launch pickplace pickplace.launch.py robot_ip:=<robot_ip_address>
....
+
This will run the pick & place program as well as the RViz window for the 3D model visualisation.
+
image::pickplace.gif[]
image::rviz3.png[]


=== Class Diagram

.Class Relations diagram
image::classrelation.png[]

[CAUTION]
The `Script` class is a class that handles the scripts to be sent to the TCP socket listener in the TM machine via the TM driver. It does not contain the pickplace program.

==== Move Class

.Explanation of Move Class
image::moveclass.png[]

The movement of the TM arm is controlled by the Move class. The `set_position` method takes in x, y, z, roll, pitch and yaw, and sends it to the listen node in the TMflow program via a service client from the TM Driver. 

[NOTE]
Queue tags and status queries were also used to ensure that no other command executes simultaneously until the motion is complete. For more information, please refer to section 8.1 of the __TM Expression Editor and Listen Node Reference Guide__ under Robot Motion Functions.

==== Transform Class

.Explanation of Transform Class
image::transformclass1.png[]
.More explanations of Transform Class
image::transformclass2.png[]

This class handles all the transforms between different frames (e.g. coordinates of the pick position relative to the robot base or vision base). The TF tree is shown below:

.TF Tree of pickplace program
image::tftree2.png[]

[NOTE]
safe_pick and safe_place transforms are the coordinates of the pick and place point with a -0.1m offset in the z-axis

==== Script Class

.Explanation of Script Class
image::scriptclass.png[]

The Script class uses the external scripts function of the TM Driver to run external commands.

[NOTE]
The script class is capable of sending instructions to run TM movement commands, however the TM SetPosition service client from the tmr_ros2 package is preferred as the format of the parameters are easier to configure and use.

==== Modbus Class

.Explanation of Modbus
image::modbusclass.png[]

The modbus class handles modbus communication between the client (TM machine) and server (user's computer). It allows for asynchronous control of many features of the TM robot.

[NOTE]
The TM Driver provides services to open and close the IO gripper. However, modbus control of the IO is preferred as it does not require the TM Driver to be running concurrently with the program, as running the TM Driver to control the IO would require the TMflow program to be in the listen node, which prevents the TM robot from being able to be manually moved to the setup locations during the setup stage.

==== IO Class

The IO class creates a client to the modbus server to open and close the Robotiq IO gripper. It serves to simplify the API for interfacing with the TM robot.

==== Pickplace Driver class

The Pickplace driver class serves to gather the classes listed above to provide a consolidated interface for interacting with the TM robot. 